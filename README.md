# ğŸ¦™ LlamaFarm - Build Powerful AI Locally, Deploy Anywhere

<div align="center">
  <img src="docs/images/rocket-llama.png" alt="Llama Building a Rocket" width="400">

  **Empowering developers to build production-ready AI applications with complete local control**

  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
  [![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
  [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)
  [![Discord](https://img.shields.io/discord/1234567890?color=7289da&logo=discord&logoColor=white)](https://discord.gg/llamafarm)

   [Getting Started](#-getting-started) â€¢ [Features](#-features) â€¢ [Contributing](#-contributing)
</div>

---

## ğŸš€ What is LlamaFarm?

LlamaFarm is a comprehensive, modular framework for building AI Projects that run locally, collaborate, and deploy anywhere. We provide battle-tested components for RAG systems, vector databases, model management, prompt engineering, and soon fine-tuning - all designed to work seamlessly together or independently.

### ğŸ¯ Our Mission

We believe AI development should be:
- **Local First**: Full control over your data and models
- **Production Ready**: Built for scale from day one
- **Developer Friendly**: Configuration over code, with sensible defaults
- **Modular**: Use what you need, ignore what you don't
- **Open**: No vendor lock-in, works with any provider

## ğŸ—ï¸ Building in the Open

We're building LlamaFarm in public! Join us:
- ğŸ› [Report bugs](https://github.com/llama-farm/llamafarm/issues)
- ğŸ’¡ [Request features](https://github.com/llama-farm/llamafarm/discussions)
- ğŸ¤ [Contribute code](CONTRIBUTING.md)
- ğŸ’¬ [Join our Discord](https://discord.gg/llamafarm)

---

## ğŸš€ Quick Start

### Install the CLI

Get started with LlamaFarm in seconds:

```bash
curl -fsSL https://raw.githubusercontent.com/llamafarm/llamafarm/main/install.sh | bash
```

After installation, verify it works:
```bash
lf version
lf help
```

For detailed installation options and troubleshooting, see the [Installation Guide](INSTALL.md).

### Your First Project

```bash
# Initialize a new project
lf init my-ai-project
cd my-ai-project

# Start the designer interface
lf designer start
```

---

## âœ¨ Features

### ğŸ” RAG (Retrieval-Augmented Generation)
*Transform any document into AI-accessible knowledge*

- **ğŸ“„ Universal Document Support**: Parse PDFs, CSVs, Word docs, web pages, and more
- **ğŸ§© Modular Pipeline**: Mix and match parsers, embedders, and vector stores
- **ğŸ¯ Smart Retrieval**: 5+ retrieval strategies including hybrid search and re-ranking
- **ğŸ”Œ Database Agnostic**: Works with ChromaDB, Pinecone, Weaviate, Qdrant, and more
- **ğŸ“Š Local Extractors**: 5 built-in extractors for metadata enrichment without LLMs
- **âš¡ Production Ready**: Batch processing, error handling, and progress tracking

**Quick Example:**
```bash
# Ingest documents with smart extraction
uv run python rag/cli.py ingest documents/ --extractors keywords entities statistics

# Search with advanced retrieval
uv run python rag/cli.py search "How does the authentication system work?" --top-k 5
```

[Learn more about RAG â†’](rag/README.md)

### ğŸ¤– Model Management
*Run and manage AI models locally or in the cloud*

- **ğŸŒ Multi-Provider Support**: OpenAI, Anthropic, Google, Cohere, Together, Groq, Ollama, HuggingFace
- **ğŸ’° Cost Optimization**: Automatic provider fallbacks and smart routing
- **ğŸ“Š Usage Tracking**: Monitor tokens, costs, and performance
- **ğŸ”„ Load Balancing**: Distribute requests across multiple providers
- **ğŸ›ï¸ Fine Control**: Rate limiting, retry logic, and timeout management
- **ğŸ  Local Models**: Full support for Ollama and HuggingFace models

**Quick Example:**
```yaml
# config/models.yaml
providers:
  primary:
    provider: "openai"
    model: "gpt-4o-mini"
    fallback_to: "local_llama"

  local_llama:
    provider: "ollama"
    model: "llama3.2"
    temperature: 0.7
```

[Learn more about Models â†’](models/README.md)

### ğŸ“ Prompt Engineering
*Enterprise-grade prompt management system*

- **ğŸ“š 20+ Templates**: Pre-built templates for common use cases
- **ğŸ§  Smart Selection**: Context-aware template selection
- **ğŸ”„ A/B Testing**: Built-in experimentation framework
- **ğŸ¯ 6 Template Categories**: Basic, Chat, Few-shot, Advanced, Domain-specific, Agentic
- **ğŸ¤ Multi-Agent Support**: Coordinate multiple AI agents
- **ğŸ“Š Evaluation Tools**: 5 evaluation templates for quality assessment

**Quick Example:**
```bash
# List all templates
uv run python prompts/cli.py template list

# Execute with smart selection
uv run python prompts/cli.py execute "Analyze this medical report" --domain medical

# Evaluate responses
uv run python prompts/cli.py evaluate "AI response text" --template llm_judge
```

[Learn more about Prompts â†’](prompts/README.md)

### ğŸ“ Fine-Tuning (Coming Soon!)
*Train custom models on your data*

- **ğŸ”§ Local Training**: Fine-tune models on your hardware
- **â˜ï¸ Cloud Training**: Integration with major training platforms
- **ğŸ“Š Dataset Management**: Tools for data preparation and validation
- **ğŸ¯ Task-Specific Models**: Optimize for your specific use case
- **ğŸ“ˆ Training Analytics**: Monitor loss, accuracy, and other metrics

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- [uv](https://github.com/astral-sh/uv) (recommended) or pip
- Optional: Ollama for local models
- Optional: Docker for containerized deployment

### Quick Install

```bash
# Clone the repository
git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Set up RAG system
cd rag
uv sync
./setup_and_demo.sh

# Set up Models system
cd ../models
uv sync
./setup_and_demo.sh

# Set up Prompts system
cd ../prompts
uv sync
./setup_and_demo.sh
```

### ğŸ® Try It Out

```bash
# RAG: Ingest and search documents
cd rag
uv run python cli.py ingest samples/documents.pdf
uv run python cli.py search "What are the key findings?"

# Models: Chat with multiple providers
cd ../models
uv run python cli.py chat --provider openai "Explain quantum computing"
uv run python cli.py chat --provider ollama "Write a Python function"

# Prompts: Use intelligent templates
cd ../prompts
uv run python -m prompts.cli execute "Compare solar vs wind energy" \
  --template comparative_analysis
```

---

## ğŸ“š Documentation

### Component Guides
- ğŸ“– [RAG System Guide](rag/README.md) - Document processing and retrieval
- ğŸ¤– [Models Guide](models/README.md) - Model management and providers
- ğŸ“ [Prompts Guide](prompts/README.md) - Prompt engineering and templates

### Tutorials
- ğŸ“ [Building Your First RAG App](docs/tutorials/first-rag-app.md)
- ğŸ”§ [Setting Up Local Models](docs/tutorials/local-models.md)
- ğŸ¯ [Prompt Engineering Best Practices](docs/tutorials/prompt-engineering.md)

### API Reference
- ğŸ”Œ [RAG API](docs/api/rag.md)
- ğŸ¤– [Models API](docs/api/models.md)
- ğŸ“ [Prompts API](docs/api/prompts.md)

---

## ğŸ› ï¸ Architecture

LlamaFarm follows a modular, configuration-driven architecture:

```
llamafarm/
â”œâ”€â”€ rag/              # Document processing and retrieval
â”‚   â”œâ”€â”€ core/         # Base classes and interfaces
â”‚   â”œâ”€â”€ parsers/      # Document parsers (PDF, CSV, etc.)
â”‚   â”œâ”€â”€ embedders/    # Text embedding models
â”‚   â”œâ”€â”€ stores/       # Vector database integrations
â”‚   â””â”€â”€ retrieval/    # Retrieval strategies
â”‚
â”œâ”€â”€ models/           # Model management
â”‚   â”œâ”€â”€ providers/    # LLM provider integrations
â”‚   â”œâ”€â”€ config/       # Configuration system
â”‚   â”œâ”€â”€ monitoring/   # Usage tracking and analytics
â”‚   â””â”€â”€ optimization/ # Cost and performance optimization
â”‚
â”œâ”€â”€ prompts/          # Prompt engineering
â”‚   â”œâ”€â”€ templates/    # Prompt template library
â”‚   â”œâ”€â”€ strategies/   # Template selection strategies
â”‚   â”œâ”€â”€ evaluation/   # Response evaluation tools
â”‚   â””â”€â”€ agents/       # Multi-agent coordination
â”‚
â””â”€â”€ training/         # Fine-tuning (coming soon)
    â”œâ”€â”€ datasets/     # Dataset management
    â”œâ”€â”€ trainers/     # Training implementations
    â””â”€â”€ evaluation/   # Model evaluation
```

---

## ğŸŒŸ Why LlamaFarm?

### For Developers
- **ğŸ  Local First**: Run everything on your machine, no API keys required
- **ğŸ”§ Hackable**: Clean, modular code that's easy to understand and extend
- **ğŸ“¦ Batteries Included**: Pre-built components for common use cases
- **ğŸ¯ Production Ready**: Built with scale, monitoring, and reliability in mind

### For Teams
- **ğŸ’° Cost Control**: Optimize spending with multi-provider support
- **ğŸ”’ Data Privacy**: Keep sensitive data on-premise
- **ğŸš€ Fast Iteration**: Hot-reload configs, no redeploys needed
- **ğŸ“Š Full Visibility**: Built-in monitoring and analytics

### For Enterprises
- **ğŸ¢ Multi-Tenant**: Isolated environments for different teams
- **ğŸ” Security First**: SOC2-ready with audit logging
- **ğŸ“ˆ Scalable**: From laptop to cluster without code changes
- **ğŸ¤ Vendor Neutral**: No lock-in, works with any provider

---

## ğŸ¤ Contributing

<div align="center">
  <img src="docs/images/iron-workers-llama.png" alt="Iron Worker Llamas" width="400">

  **Join our herd of contributors building the future of local AI!**
</div>

We love contributions! Whether you're fixing bugs, adding features, or improving documentation, we'd love to have you aboard.

### How to Contribute
1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/amazing-feature`)
3. ğŸ’» Make your changes
4. âœ… Run tests (`uv run pytest`)
5. ğŸ“ Commit your changes (`git commit -m 'Add amazing feature'`)
6. ğŸš€ Push to the branch (`git push origin feature/amazing-feature`)
7. ğŸ‰ Open a Pull Request

See our [Contributing Guide](CONTRIBUTING.md) for more details.

### Good First Issues
- ğŸ·ï¸ [good-first-issue](https://github.com/llama-farm/llamafarm/labels/good-first-issue)
- ğŸ“š [documentation](https://github.com/llama-farm/llamafarm/labels/documentation)
- ğŸ§ª [testing](https://github.com/llama-farm/llamafarm/labels/testing)

---

## ğŸ‘¥ Contributors

Thanks to all our amazing contributors who make LlamaFarm possible!

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align="center" valign="top" width="14.28%"><a href="https://github.com/contributor1"><img src="https://avatars.githubusercontent.com/contributor1?v=4?s=100" width="100px;" alt="Contributor 1"/><br /><sub><b>Contributor 1</b></sub></a><br /><a href="https://github.com/llama-farm/llamafarm/commits?author=contributor1" title="Code">ğŸ’»</a></td>
      <!-- Add more contributors here -->
    </tr>
  </tbody>
</table>
<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->
<!-- ALL-CONTRIBUTORS-LIST:END -->

---

## ğŸ™ Open Source Credits

LlamaFarm is built on the shoulders of giants. Special thanks to:

### Core Dependencies
- ğŸ¦œ [LangChain](https://github.com/hwchase17/langchain) - LLM orchestration
- ğŸ¤— [Transformers](https://github.com/huggingface/transformers) - Model library
- ğŸ¯ [ChromaDB](https://github.com/chroma-core/chroma) - Vector database
- ğŸ“Š [Pandas](https://github.com/pandas-dev/pandas) - Data manipulation
- ğŸ”¥ [PyTorch](https://github.com/pytorch/pytorch) - Deep learning

### Development Tools
- ğŸš€ [uv](https://github.com/astral-sh/uv) - Fast Python package management
- ğŸ§ª [pytest](https://github.com/pytest-dev/pytest) - Testing framework
- ğŸ“ [Pydantic](https://github.com/pydantic/pydantic) - Data validation
- ğŸ¨ [Rich](https://github.com/Textualize/rich) - Beautiful terminal output

See [CREDITS.md](CREDITS.md) for a complete list.

---

## ğŸ“„ License

LlamaFarm is MIT licensed. See [LICENSE](LICENSE) for details.

---



## ğŸ’¬ Community

Join the LlamaFarm community:

- ğŸ’¬ [Discord Server](https://discord.gg/llamafarm) - Chat with the community


---

<div align="center">
  <p>
    <b>Ready to farm some AI? ğŸ¦™ğŸšœ</b>
  </p>
  <p>
    <a href="https://github.com/llama-farm/llamafarm">â­ Star us on GitHub</a> â€¢
    <a href="https://discord.gg/llamafarm">ğŸ’¬ Join Discord</a> â€¢
  </p>
</div>