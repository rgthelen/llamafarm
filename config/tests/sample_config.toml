version = "v1"

name = "sample_config"
namespace = "test"

[[prompts]]
name = "customer_support"
content = "You are a helpful customer support assistant. Answer questions politely and accurately based on the provided context."
prompt = "You are a helpful customer support assistant. Answer questions politely and accurately based on the provided context."
description = "Default customer support prompt for handling user inquiries"

[[prompts]]
name = "technical_documentation"
content = "You are a technical documentation assistant. Provide clear, accurate, and detailed explanations of technical concepts."
prompt = "You are a technical documentation assistant. Provide clear, accurate, and detailed explanations of technical concepts."
description = "Prompt for generating technical documentation and explanations"

[[prompts]]
name = "code_review"
content = "You are a code review assistant. Analyze code for best practices, potential bugs, and improvements."
prompt = "You are a code review assistant. Analyze code for best practices, potential bugs, and improvements."
description = "Prompt for conducting code reviews and providing feedback"

[rag]

[[rag.strategies]]
name = "default"
description = "Customer support strategy for testing"

[rag.strategies.components.parser]
type = "CSVParser"

[rag.strategies.components.parser.config]
content_fields = ["question", "answer", "solution", "explanation"]
metadata_fields = ["category", "timestamp", "priority", "tags", "author"]
id_field = "id"
combine_content = true
content_separator = "\n\n"


[rag.strategies.components.embedder]
type = "OllamaEmbedder"

[rag.strategies.components.embedder.config]
model = "mxbai-embed-large"
base_url = "http://localhost:11434"
batch_size = 32
timeout = 60

[rag.strategies.components.vector_store]
type = "ChromaStore"

[rag.strategies.components.vector_store.config]
collection_name = "customer_support_knowledge_base"
persist_directory = "./data/vector_store/chroma"

[rag.strategies.components.retrieval_strategy]
type = "BasicSimilarityStrategy"

[rag.strategies.components.retrieval_strategy.config]
distance_metric = "cosine"

[[models]]
provider = "local"
model = "llama3.1:8b"

[[models]]
provider = "local"
model = "llama3.1:70b"

[[models]]
provider = "openai"
model = "gpt-4"

[[models]]
provider = "openai"
model = "gpt-4o-mini-turbo"

[[models]]
provider = "anthropic"
model = "claude-3-sonnet-20240229"

[[models]]
provider = "anthropic"
model = "claude-3-haiku-20240307"

[[models]]
provider = "google"
model = "gemini-pro"

[[models]]
provider = "custom"
model = "custom-fine-tuned-model-v1"

[[datasets]]
name = "sample_dataset"
files = ["test_file.csv"]
rag_strategy = "default"

[runtime]
provider = "openai"
model = "llama3.1:8b"
api_key = "ollama"
base_url = "http://localhost:11434/v1"
[runtime.model_api_parameters]
temperature = 0.5
